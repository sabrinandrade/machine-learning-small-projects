{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTELIVIX CHALLENGE (MID LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No NLTK (Natural Language Toolkit), uma plataforma para desenvolvimento de aplicações voltada para Processamento de Linguagem Natural para Python, estão disponíveis alguns corpora com textos já classificados, \"taggeados\", etc. Um deles, o corpus “Brown”, reune 500 textos de diferentes categorias.\n",
    "\n",
    "### O desafio consiste em:\n",
    "* Identificar as 2 categorias mais frequentes, extrair os textos pertencentes a cada uma dessas categorias;\n",
    "* Criar uma base de treino (66% do total dos textos) e uma base de teste (os 34% restantes); Os textos devem ser distribuídos aleatoriamente em ambas as bases;\n",
    "* Criar um classificador capaz de categorizar o conjuntos de teste.\n",
    "* O treinamento deve possuir duas etapas:\n",
    "\n",
    "### Pré-processamento:\n",
    "* Extrair tokens, eliminando pontuações, stopwords e realizando stemming (ou stemização) nos termos restantes;\n",
    "* Os textos de treinamento, representados por listas dos tokens restantes, devem ser convertidos em uma matriz TF-IDF (Text Frequency – Inverse Document Frequency). (Implementar a parte de IDF do algoritmo caso não encontre similar em outra biblioteca.)\n",
    "* Classificação:\n",
    "* Cada linha da matriz, que representa um documento da base de treinamento, deve ser apresentada a um classificador juntamente com sua categoria, de forma que ocorra o aprendizado.\tO teste do classificador deve seguir o mesmo raciocínio.\n",
    "\n",
    "### Sobre a entrega:\n",
    "* Deve-se escolher 3 diferentes classificadores, treiná-los, testá-los e reportar os resultados, comparando-os e escolhendo o melhor, justificando a escolha.\n",
    "* Para as comparações, deve-se calcular uma matriz de confusão para cada classificador.\n",
    "* Evidentemente, outras métricas adicionais que, por ventura, sejam consideradas necessárias, podem ser utilizadas.\n",
    "* Os códigos e o relatório devem ser entregues em um ipython notebook, o qual deve ser auto-suficiente para ser executado (assumindo que o computador a executar possua todas as ferramentas necessárias instaladas).\n",
    "\n",
    "### Ferramentas sugeridas:\n",
    "* NLTK (pré-processamento – alguns dos passos estão implementados, outros não);\n",
    "* scikit-learn (classificação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from scipy.stats import *\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_used_categories(corpus):\n",
    "    most_used = []    \n",
    "    for genre in corpus.categories():\n",
    "        most_used.append((genre, len(corpus.fileids(categories=genre))))\n",
    "    most_used.sort(key=itemgetter(1), reverse=True)\n",
    "    return [most_used[0][0], most_used[1][0]]\n",
    "\n",
    "\n",
    "def tokenize_and_stem_text(text):\n",
    "    text = [(re.sub(r'\\d+', '', word.translate(str.maketrans('', '', string.punctuation)))).lower() for word in text]\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords.words('english') and word != '']\n",
    "    return set(text)\n",
    "\n",
    "\n",
    "def train_and_test_classifier(classifier):\n",
    "    classifier.fit(X_train_transformed, y_train)\n",
    "    print (\"Test accuracy:\", classifier.score(X_test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learned', 'belles_lettres']\n"
     ]
    }
   ],
   "source": [
    "corpus = brown\n",
    "categories = []\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "tfidf = TfidfVectorizer(max_df=0.5)\n",
    "\n",
    "dataset = []\n",
    "inputset = []\n",
    "outputset = []\n",
    "\n",
    "categories = most_used_categories(corpus)\n",
    "print(categories)\n",
    "\n",
    "for category in categories:\n",
    "    for fileid in corpus.fileids(categories = category):\n",
    "        dataset.append([corpus.words(fileids = fileid), category])\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i][0] = tokenize_and_stem_text(dataset[i][0])\n",
    "    inputset.append(' '.join(map(str, dataset[i][0])))\n",
    "    outputset.append(dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputset, \n",
    "                                                    outputset, \n",
    "                                                    test_size=0.34, \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_transformed = tfidf.fit_transform(X_train)\n",
    "X_test_transformed = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "svm_model = svm.SVC(C=0.8, \n",
    "                    random_state=1234,\n",
    "                    kernel='linear')\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(35, ), \n",
    "                          activation=\"relu\", \n",
    "                          solver=\"adam\", \n",
    "                          alpha=0.65, \n",
    "                          max_iter=1000, \n",
    "                          random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.603773584906\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "train_and_test_classifier(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.830188679245\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "train_and_test_classifier(svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.867924528302\n"
     ]
    }
   ],
   "source": [
    "# Multi-Layer Perceptron\n",
    "train_and_test_classifier(mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_predicted = tree_model.predict(X_test_transformed)\n",
    "svm_predicted = svm_model.predict(X_test_transformed)\n",
    "mlp_predicted = mlp_model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE\n",
      "[[16  9]\n",
      " [12 16]]\n",
      "\n",
      "SUPPORT VECTOR MACHINE\n",
      "[[24  1]\n",
      " [ 8 20]]\n",
      "\n",
      "MULTI-LAYER PERCEPTRON\n",
      "[[23  2]\n",
      " [ 5 23]]\n"
     ]
    }
   ],
   "source": [
    "print(\"DECISION TREE\")\n",
    "#print(metrics.classification_report(y_test, tree_predicted))\n",
    "print(metrics.confusion_matrix(y_test, tree_predicted))\n",
    "\n",
    "print(\"\\nSUPPORT VECTOR MACHINE\")\n",
    "#print(metrics.classification_report(y_test, svm_predicted))\n",
    "print(metrics.confusion_matrix(y_test, svm_predicted))\n",
    "\n",
    "print(\"\\nMULTI-LAYER PERCEPTRON\")\n",
    "#print(metrics.classification_report(y_test, mlp_predicted))\n",
    "print(metrics.confusion_matrix(y_test, mlp_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comentários\n",
    "\n",
    "* Palavras com frequência acima de 50% não foram selecionados para a matriz TF-IDF.\n",
    "* Considerando a matriz de confusão e a taxa de classificação, a MLP seria o modelo escolhido apesar do maior tempo de treinamento. Contudo, é necessário conduzir testes estatísticos nos resultados dos dois modelos (além de realizar outros ajustes nos parâmetros) para verificar se o ganho da MLP em relação a SVM é relevante para justificar a escolha de um modelo com maior tempo de processamento.\n",
    "* Os parâmetros da SVM e da MLP foram escolhidos de forma empírica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
